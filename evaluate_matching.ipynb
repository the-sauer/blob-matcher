{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "043c31c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor to positive matching for image 0 FPR=0.475862056016922\n",
      "Anchor to positive matching for image 1 FPR=0.9770833253860474\n",
      "Anchor to positive matching for image 2 FPR=0.7494692206382751\n",
      "Anchor to positive matching for image 3 FPR=0.023463686928153038\n",
      "Anchor to positive matching for image 4 FPR=0.8358209133148193\n",
      "Anchor to positive matching for image 5 FPR=0.42391303181648254\n",
      "Anchor to positive matching for image 6 FPR=0.9842519760131836\n",
      "Anchor to positive matching for image 7 FPR=0.8828282952308655\n",
      "Anchor to positive matching for image 8 FPR=0.8045454621315002\n",
      "Anchor to positive matching for image 9 FPR=0.9756097793579102\n",
      "Anchor to positive matching over all images FPR=0.7369179129600525\n"
     ]
    }
   ],
   "source": [
    "from modules.hardnet.losses import distance_matrix_vector\n",
    "from modules.hardnet.models import HardNet\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = HardNet(transform=\"PTN\", coords=\"log\", patch_size=32, scale=128)\n",
    "model.load_state_dict(torch.load(\"./data/models/2025_11_01_blobinator_128/model_checkpoint_147.pth\", weights_only=False)[\"state_dict\"])\n",
    "model.to(device)\n",
    "positive_path_regex = re.compile(\"(\\\\d+)_(\\\\d+).png\")\n",
    "dataset_path = \"./data/very_hard/validation\"\n",
    "patch_files = os.listdir(os.path.join(dataset_path, \"patches/128/positives\"))\n",
    "\n",
    "overall_anchor_features = []\n",
    "overall_positive_features = []\n",
    "all_anchor_patches = []\n",
    "all_positive_patches = []\n",
    "overall_garbage_features = []\n",
    "\n",
    "for i in range(10):\n",
    "    regex = re.compile(f\"{i:04}_\\\\d+\\\\.png\")\n",
    "    patches = list(filter(lambda f: regex.match(f) is not None, patch_files))\n",
    "\n",
    "    anchor_patches = torch.empty((len(patches), 1, 32, 32)).to(device)\n",
    "    positive_patches = torch.empty((len(patches), 1, 32, 32)).to(device)\n",
    "\n",
    "    for j, patch_file in enumerate(patches):\n",
    "        match = positive_path_regex.search(os.path.basename(patch_file))\n",
    "        board_idx, blob_idx = match.group(1), match.group(2)\n",
    "        positive_patches[j] = torchvision.io.decode_image(os.path.join(dataset_path, f\"patches/128/positives/{board_idx}_{blob_idx}.png\"), torchvision.io.ImageReadMode.GRAY).to(torch.float32) / 255\n",
    "        anchor_patches[j] = torchvision.io.decode_image(os.path.join(dataset_path, f\"patches/128/anchors/{board_idx}_{blob_idx}.png\"), torchvision.io.ImageReadMode.GRAY).to(torch.float32) / 255\n",
    "    garbage_patch_files = os.listdir(os.path.join(dataset_path, \"patches/128/garbage\"))\n",
    "    garbage_patch_files = list(filter(lambda f: regex.match(f) is not None, garbage_patch_files))\n",
    "    garbage_patches = torch.empty((len(garbage_patch_files), 1, 32, 32))\n",
    "    for j, patch_file in enumerate(garbage_patch_files):\n",
    "        garbage_patches[j] = torchvision.io.decode_image(os.path.join(dataset_path, f\"patches/128/garbage/{patch_file}\"), torchvision.io.ImageReadMode.GRAY)\n",
    "\n",
    "    all_anchor_patches.append(anchor_patches)\n",
    "\n",
    "    anchor_features, _ = model(anchor_patches)\n",
    "    positive_features, _ = model(positive_patches)\n",
    "    garbage_features, _ = model(garbage_patches)\n",
    "\n",
    "    overall_anchor_features.append(anchor_features)\n",
    "    overall_positive_features.append(positive_features)\n",
    "    overall_garbage_features.append(garbage_features)\n",
    "\n",
    "    distances = distance_matrix_vector(anchor_features, torch.concat((positive_features, garbage_features)))\n",
    "    # indices = distances.argsort(dim=0)\n",
    "    # matches = torch.stack([torch.arange(0, anchor_features.size(0), dtype=int).to(device), indices[0]])\n",
    "    # true_positives = torch.where(matches[0] == matches[1], 1, 0).sum()\n",
    "    # false_positives = torch.where(matches[0] != matches[1], 1, 0).sum()\n",
    "    # print(f\"Positive to anchor matching for image {i} FPR={false_positives / (true_positives + false_positives)}\")\n",
    "\n",
    "    # # distances = distance_matrix_vector(anchor_features, positive_features)\n",
    "    indices = distances.argsort(dim=1)\n",
    "    matches = torch.stack([torch.arange(0, positive_features.size(0), dtype=int).to(device), indices[:,0]])\n",
    "    true_positives = torch.where(matches[0] == matches[1], 1, 0).sum()\n",
    "    false_positives = torch.where(matches[0] != matches[1], 1, 0).sum()\n",
    "    print(f\"Anchor to positive matching for image {i} FPR={false_positives / (true_positives + false_positives)}\")\n",
    "\n",
    "distances = distance_matrix_vector(torch.concat(overall_anchor_features), torch.concat(overall_positive_features + overall_garbage_features))\n",
    "\n",
    "indices = distances.argsort(dim=1)\n",
    "matches = torch.stack([torch.arange(0, distances.size(0), dtype=int).to(device), indices[:,0]])\n",
    "true_positives = torch.where(matches[0] == matches[1], 1, 0).sum()\n",
    "false_positives = torch.where(matches[0] != matches[1], 1, 0).sum()\n",
    "print(f\"Anchor to positive matching over all images FPR={false_positives / (true_positives + false_positives)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
